% --------------------------------------------------------------- %
% Heart Protectors - Final Report
% --------------------------------------------------------------- %
\documentclass[11pt,a4paper]{article}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{etoolbox}
\AtBeginEnvironment{algorithm}{\footnotesize}
\AtBeginEnvironment{algorithmic}{\footnotesize}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage[most]{tcolorbox} % Add 'most' option to load all features
\usepackage{caption}
\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{abstract}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{float}
\usepackage{pifont} % Required for checkmark
\usepackage[export]{adjustbox}  % gives \includegraphics the roundcorner key

% Fix header height
\setlength{\headheight}{14pt}

% Highlighting
\definecolor{lightyellow}{rgb}{1,1,0.8}
\newcommand{\highlight}[1]{\colorbox{lightyellow}{$\displaystyle #1$}}

% Define green checkmark
\newcommand{\greencheck}{\textcolor{green}{\ding{52}}}

% Colors
\definecolor{lightblue}{rgb}{0.85,0.90,0.95}
\definecolor{mediumblue}{rgb}{0.70,0.80,0.90}
\definecolor{darkblue}{rgb}{0.20,0.40,0.65}
\definecolor{lightgreen}{rgb}{0.85,0.95,0.85}
\definecolor{mediumgreen}{rgb}{0.70,0.85,0.70}
\definecolor{darkgreen}{rgb}{0.20,0.65,0.40}
\definecolor{lightpurple}{rgb}{0.90,0.85,0.95}
\definecolor{mediumpurple}{rgb}{0.80,0.70,0.85}
\definecolor{lightgray}{rgb}{0.95,0.95,0.95}
\definecolor{mediumgray}{rgb}{0.85,0.85,0.85}

% Code listing style - Changed to Python
\lstset{
    language=Python,
    breaklines=true,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue},
    identifierstyle=\color{black},
    commentstyle=\color[rgb]{0.133,0.545,0.133},
    stringstyle=\color{red},
    tabsize=4,
    showspaces=false,
    showstringspaces=false,
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    backgroundcolor=\color{lightgray},
    escapeinside={(*@}{@*)}
}

% Custom environment for consistent indentation
\newenvironment{indented}
  {\begin{list}{}{\leftmargin=1em \rightmargin=1em}\item[]}
  {\end{list}}

% Format settings
\onehalfspacing
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

% Title setup - improved compact version
\makeatletter
\renewcommand{\maketitle}{
  \begin{center}
    \vspace*{-0.25in} % Reduce top space
    {\LARGE \textbf{\@title}} \\[0.3cm]
    {\large \@subtitle} \\[0.2cm]
    {\normalsize \textit{\@author}} \\[0.1cm]
    {\normalsize \@date} \\
  \end{center}
  \vspace{0.3cm} % Space after title block
}
\makeatother

% Add subtitle command
\newcommand{\subtitle}[1]{\def\@subtitle{#1}}
\def\@subtitle{}

% Fancy headers
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Heart Failure Risk Prediction Project}
\fancyhead[R]{Team Heart Protectors - Final Report}
\fancyfoot[C]{\thepage}

% Section formatting - reduce space after section titles
\titleformat{\section}{\normalfont\large\bfseries}{\thesection}{1em}{}
\titlespacing*{\section}{0pt}{12pt}{3pt} % Reduced space after section title from default

% Subsection formatting - reduce space after subsection titles
\titleformat{\subsection}{\normalfont\normalsize\bfseries}{\thesubsection}{1em}{}
\titlespacing*{\subsection}{0pt}{12pt}{3pt} % Reduced space after subsection title

% Simpler tcolorbox styles
\tcbset{
  infobox/.style={
    colback=lightblue!30,
    colframe=darkblue,
    fonttitle=\bfseries\sffamily,
    boxrule=0.5pt,
    title=#1
  }
}

\tcbset{
  notebox/.style={
    colback=lightgreen!30,
    colframe=darkgreen,
    fonttitle=\bfseries\sffamily,
    boxrule=0.5pt,
    title=#1
  }
}

% Begin document
\begin{document}

% Add project cover image at the top
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{./pictures/cover.png}
\end{figure}




% Set title, subtitle, author, and date
\title{Heart Failure Risk Prediction Using Ma chine Learning Techniques}
\subtitle{Team Meeting Report – Final Report}
\author{Team Heart Protectors}
\date{April 23, 2025}

% \maketitle
% \vspace*{-0.2in}

\begin{tabular}{ll}
    \textbf{Team Name:}         & Heart Protectors    \\
    \textbf{Team Leader:}       & Thien Van Ky Nguyen \\
    \textbf{Team Members:}      & ?, ?, ?, ?          \\
    \textbf{Meeting Date/Time:} & April 23, 2025      \\
    \textbf{Attendees:}         & All team members
\end{tabular}

\section{Project Topic / Service Scenario}

Our project uses several machine learning models to predict heart failure
risks from health data.
Heart failure is a big health problem worldwide that affects
millions of people and puts a huge strain on hospitals and
healthcare systems.
Current methods for detecting heart failure risk
aren't great at catching problems early,
which means patients often don't get help until it's too late.

We're building a tool that can spot
people who might be at risk of heart failure by
looking at their health information.
This could help doctors take action sooner
with patients who are at high risk, possibly
preventing heart failure from happening in the first
place and saving lives.
% The system uses machine learning to analyze
% health data and calculate risk scores that
% doctors could use alongside their regular patient information systems.

\section{Selected Dataset}

\begin{tcolorbox}[notebox={Dataset Information}]
    For this project, we utilize a single, comprehensive heart disease dataset from Kaggle to build and validate our predictive models:
    \vspace{-0.25cm}
    \begin{enumerate}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item \textbf{Heart Disease UCI} (10,000 entries) –
              \url{https://www.kaggle.com/datasets/oktayrdeki/heart-disease}
    \end{enumerate}
\end{tcolorbox}

\begin{table}[H]
    \centering
    \caption{Heart Disease UCI Dataset Features}
    \begin{tabular}{|p{0.45\textwidth}|p{0.45\textwidth}|}
        \hline
        \textbf{Categorical Features} & \textbf{Numerical Features} \\
        \hline
        Gender                        & Age                         \\
        Exercise Habits               & Blood Pressure              \\
        Smoking                       & Cholesterol Level           \\
        Family Heart Disease          & BMI                         \\
        Diabetes                      &                             \\
        High Blood Pressure           &                             \\
        Low HDL Cholesterol           &                             \\
        High LDL Cholesterol          &                             \\
        Stress Level                  &                             \\
        Sleep Hours                   &                             \\
        Sugar Consumption             &                             \\
        Triglyceride Level            &                             \\
        Fasting Blood Sugar           &                             \\
        CRP Level                     &                             \\
        Homocysteine Level            &                             \\
        \hline
    \end{tabular}
\end{table}

\section{Models Implemented}
The project implements the following machine learning models for heart
failure risk prediction:
\begin{itemize}
    \vspace{-0.25cm}
    \item \textbf{Neural Network (NN)}: A feed-forward multilayer perceptron trained on the UCI dataset with early stopping and dropout regularization.
    \item \textbf{Support Vector Machine (SVM)}: A kernelized SVM (linear and RBF kernels evaluated) optimized via grid search on the regularization parameter $C$ and kernel bandwidth.
\end{itemize}

\section{Problems and Challenges}

Throughout the development of our heart failure risk prediction system, we encountered various technical and methodological challenges that required careful consideration and innovative solutions.

\subsection{Data Quality and Preprocessing Challenges}

\begin{tcolorbox}[
        title=Data Quality Issues Overview,
        colback=lightpurple!30,
        colframe=mediumpurple,
        boxrule=0.5pt,
        fonttitle=\bfseries\sffamily\footnotesize,
        fontupper=\footnotesize
    ]
    Our analysis of the heart disease dataset revealed:
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item Missing values in multiple columns (19-30 entries per column)
        \item Substantial missing data in 'Alcohol Consumption' (2,586 of 10,000 entries missing)
        \item Need for proper handling of both numerical and categorical features
        \item Potential outliers requiring detection and treatment
    \end{itemize}
\end{tcolorbox}





\subsubsection{Missing Values}
\vspace{-0.25cm}
One of the most significant challenges we faced was handling missing values in our datasets. Our initial analysis of the heart disease dataset revealed varying degrees of missing data across different features. Most notably, the 'Alcohol Consumption' feature had 2,586 missing values out of 10,000 entries (approximately 25.9\%), necessitating its complete removal from the dataset to maintain overall data integrity. Other features had fewer missing values (ranging from 19 to 30 entries), but still required appropriate handling techniques.

To address this issue, we implemented a systematic approach:
\vspace{-0.25cm}
\begin{itemize}
    \item For numerical features (such as Age, Blood Pressure, Cholesterol Level, and BMI), we applied mean imputation to replace missing values with the average of each respective column.
    \item For categorical features (such as Gender, Exercise Habits, and Smoking status), we employed mode imputation, replacing missing values with the most frequently occurring category in each column.
\end{itemize}

This imputation strategy helped preserve the dataset's size while minimizing statistical bias, although we acknowledge that imputation can potentially introduce subtle distortions in the data distribution.

\begin{lstlisting}
# 1. For numerical columns - impute with mean
numerical_columns = df.select_dtypes(include=[np.number]).columns
# Fill missing values with the mean of each column
df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())

# 2. For categorical columns - impute with mode (most frequent value)
categorical_columns = df.select_dtypes(exclude=[np.number]).columns
# Fill missing values with the most frequent value (mode) for each column
for col in categorical_columns:
    df[col] = df[col].fillna(df[col].mode()[0])
\end{lstlisting}

\subsubsection{Feature Encoding and Transformation}
\vspace{-0.25cm}
Another challenge was the appropriate encoding of categorical variables for model training. Our dataset contained multiple categorical features that needed transformation into a format suitable for machine learning algorithms. While our preprocessing script identified categorical features for potential one-hot encoding, ensuring that these transformations maintained the semantic meaning of each category without introducing unintended relationships was challenging.

Additionally, proper scaling of numerical features required careful consideration to prevent features with larger magnitude ranges (like Cholesterol Level) from dominating those with smaller ranges (like Age) during model training.

\subsection{Methodological Challenges}

\subsubsection{Feature Selection}
\vspace{-0.25cm}
Determining the most predictive features for heart failure risk presented a significant challenge. Our initial approach included using ANOVA F-tests to identify statistically significant features, but the effectiveness of this method varied across different subsets of our data. The interrelationships between various health indicators complicated the feature selection process, as some features that appeared individually insignificant could become important when considered in combination with others.

\subsubsection{Model Selection and Optimization}
\vspace{-0.25cm}
Selecting the most appropriate machine learning models for heart failure prediction required balancing accuracy, interpretability, and computational efficiency. Our project implements Neural Network and Support Vector Machine models, each presenting unique challenges:

\begin{itemize}
    \item \textbf{\greencheck \space Neural Network (NN)}: Our deep learning approach required careful architecture design, including determining the optimal number of hidden layers, neurons per layer, and activation functions. Additionally, preventing overfitting through techniques like dropout and early stopping required extensive experimentation.

    \item \textbf{\greencheck \space Support Vector Machine (SVM)}: While effective for high-dimensional classification, optimizing SVM required extensive hyperparameter tuning, particularly for the regularization parameter (C) and kernel selection (linear, polynomial, RBF). Finding the right balance between model complexity and generalization capability was challenging.
\end{itemize}

\subsection{Implementation Challenges}

\subsubsection{Data Integration}
Working with multiple datasets from different sources introduced integration challenges. Variations in feature naming conventions, units of measurement, and data collection methodologies across datasets required careful harmonization to create a unified and consistent training dataset.

\subsubsection{Cross-Validation Strategy}
Implementing an appropriate cross-validation
strategy was crucial for reliable model evaluation but
presented challenges due to potential class imbalance in the
target variable (heart disease status).
Ensuring that each fold maintained representative
distributions of both positive and negative cases required
specialized stratification techniques.

\begin{tcolorbox}[infobox={Insights and Solutions}]
    Despite these challenges, our team implemented several effective solutions:
    \vspace{-0.25cm}
    \begin{itemize}
        \item a
        \item a
        \item a
        \item a
    \end{itemize}
\end{tcolorbox}

\section{Each Member's Implementation and Evaluation}

\subsection{Member 1 (Name, graduate/undergraduate)}

\begin{tcolorbox}[
        title=Neural Network Implementation,
        colback=lightblue!30,
        colframe=darkblue,
        boxrule=0.5pt,
        fonttitle=\bfseries\sffamily\footnotesize,
        fontupper=\footnotesize
    ]
    \textbf{Model and Implementation details:}

    The Neural Network model was implemented with the following key components:
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item a
        \item a
        \item a
        \item a
        \item a
    \end{itemize}

    \textbf{Evaluation Results:}
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item Accuracy:
        \item Precision:
        \item Recall:
        \item F1 Score:
        \item AUC-ROC:
    \end{itemize}
\end{tcolorbox}

\subsection{Member 2 (Name, graduate/undergraduate)}

\begin{tcolorbox}[
        title=Support Vector Machine Implementation,
        colback=lightpurple!30,
        colframe=mediumpurple,
        boxrule=0.5pt,
        fonttitle=\bfseries\sffamily\footnotesize,
        fontupper=\footnotesize
    ]
    \textbf{Model and Implementation details:}

    The SVM implementation featured:
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item a
        \item a
        \item a
        \item a
        \item a
    \end{itemize}

    \textbf{Evaluation Results:}
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item Accuracy:
        \item Precision:
        \item Recall:
        \item F1 Score:
        \item AUC-ROC:
    \end{itemize}
\end{tcolorbox}

\subsection{Member 3 (Name, graduate/undergraduate)}

\begin{tcolorbox}[
        title=Data Preprocessing and Feature Engineering,
        colback=lightgreen!30,
        colframe=darkgreen,
        boxrule=0.5pt,
        fonttitle=\bfseries\sffamily\footnotesize,
        fontupper=\footnotesize
    ]
    \textbf{Implementation details:}

    This work focused on:
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item a
        \item a
        \item a
        \item a
        \item a
    \end{itemize}

    \textbf{Evaluation Results:}
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item Accuracy:
        \item Precision:
        \item Recall:
        \item F1 Score:
        \item AUC-ROC:
    \end{itemize}
\end{tcolorbox}

\subsection{Member 4 (Name, graduate/undergraduate)}

\begin{tcolorbox}[
        title=Visualization and Model Evaluation,
        colback=mediumblue!30,
        colframe=darkblue,
        boxrule=0.5pt,
        fonttitle=\bfseries\sffamily\footnotesize,
        fontupper=\footnotesize
    ]
    \textbf{Implementation details:}

    This work focused on:
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item a
        \item a
        \item a
        \item a
        \item a
    \end{itemize}

    \textbf{Evaluation Results:}
    \begin{itemize}[leftmargin=*, itemsep=2pt, parsep=0pt]
        \item Accuracy:
        \item Precision:
        \item Recall:
        \item F1 Score:
        \item AUC-ROC:
    \end{itemize}
\end{tcolorbox}

\end{document}